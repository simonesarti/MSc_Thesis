{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from OFA_mbv3_extended.networks.layers.static_layers.stat_layers import AttentionConv, ext_set_layer_from_config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AttentonConv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### basic version, channel mult 8 and stride 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "layer = AttentionConv(3,16,7,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionConv(\n",
      "  (key_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (query_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (value_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'ATTENTIONCONV_16'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.module_str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'AttentionConv', 'in_channels': 3, 'out_channels': 16, 'kernel_size': 7, 'stride': 1, 'groups': 8, 'bias': False}\n"
     ]
    }
   ],
   "source": [
    "cfg=layer.config\n",
    "print(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "built_att = ext_set_layer_from_config(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'ATTENTIONCONV_16'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built_att.module_str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'AttentionConv',\n 'in_channels': 3,\n 'out_channels': 16,\n 'kernel_size': 7,\n 'stride': 1,\n 'groups': 8,\n 'bias': False}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built_att.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "t = torch.randn(1,3,64,64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1.0923e+00,  2.3487e+00,  3.1311e-01,  ...,  1.1464e+00,\n            1.1479e-01, -4.1332e-01],\n          [-6.6271e-01,  4.0323e-01, -4.6923e-01,  ..., -1.0038e+00,\n            7.5443e-01, -3.3653e+00],\n          [-1.1367e+00, -7.2288e-01, -5.7959e-01,  ..., -5.3277e-01,\n           -1.0396e+00,  2.7559e-01],\n          ...,\n          [-1.0068e+00, -4.0013e-01, -2.5122e-01,  ..., -1.7632e+00,\n           -6.1049e-01, -2.2122e-01],\n          [ 2.5781e-01, -2.9430e-01,  7.1521e-01,  ...,  1.0440e+00,\n            1.2279e+00,  1.8835e+00],\n          [ 3.4084e-01, -4.5594e-01, -1.8271e+00,  ...,  6.5703e-01,\n           -6.3943e-01, -4.7031e-01]],\n\n         [[ 1.3194e-01,  9.4330e-01, -1.3060e+00,  ..., -2.0041e+00,\n            5.9981e-01, -8.1051e-01],\n          [ 3.2729e-01,  1.8101e-01, -9.1574e-01,  ..., -6.7578e-01,\n            1.9352e+00, -9.8398e-02],\n          [-1.9830e-01,  9.4317e-01, -1.9220e-01,  ...,  1.5503e+00,\n           -4.7824e-02,  7.2311e-01],\n          ...,\n          [ 1.9782e+00,  3.3592e-01,  1.2141e-01,  ..., -1.3059e-01,\n           -3.8847e-02, -1.2324e+00],\n          [-1.0865e+00, -8.1884e-01,  2.0574e+00,  ..., -3.0330e-01,\n            6.0412e-01, -1.4300e+00],\n          [-7.0745e-01, -8.3962e-01, -7.3531e-01,  ...,  1.7143e-01,\n           -2.4971e+00, -3.8553e-01]],\n\n         [[-2.7600e-01,  8.7932e-01, -3.1976e-01,  ...,  1.1268e+00,\n            1.6672e-02,  3.3645e-01],\n          [-1.2755e+00, -6.2911e-01,  8.7226e-01,  ..., -5.7672e-01,\n            7.6461e-01,  4.7908e-02],\n          [-1.7586e+00, -1.3809e+00, -8.9245e-02,  ...,  2.5632e-03,\n            1.6452e-01,  1.9749e+00],\n          ...,\n          [-2.2886e-02, -4.5105e-01, -4.0220e-01,  ...,  1.1299e+00,\n            5.7678e-01,  1.0398e+00],\n          [ 2.1025e+00,  1.4757e+00, -1.2266e+00,  ...,  4.0703e-01,\n            1.5550e+00,  4.7156e-01],\n          [-1.2157e+00,  1.2865e-01,  6.2121e-01,  ..., -4.9359e-01,\n            5.0535e-01, -9.4996e-01]]]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 64, 64])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(t).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "### channel mult 8 and stride 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "layer2 = AttentionConv(3,16,7,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "AttentionConv(\n  (key_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (query_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (value_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'AttentionConv',\n 'in_channels': 3,\n 'out_channels': 16,\n 'kernel_size': 7,\n 'stride': 2,\n 'groups': 8,\n 'bias': False}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 32, 32])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(t).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "cfg2 = layer2.config\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "built2 =  ext_set_layer_from_config(cfg2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'ATTENTIONCONV_16'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built2.module_str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'AttentionConv',\n 'in_channels': 3,\n 'out_channels': 16,\n 'kernel_size': 7,\n 'stride': 2,\n 'groups': 8,\n 'bias': False}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built2.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 32, 32])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(t).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### channel not mult 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-201614a8091f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlayer3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAttentionConv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m17\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\thesis\\OFA_mbv3_extended\\networks\\layers\\static_layers\\stat_layers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, in_channels, out_channels, kernel_size, stride, groups, bias)\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m         \u001B[1;32massert\u001B[0m \u001B[0mout_channels\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mgroups\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrel_h\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mParameter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_channels\u001B[0m \u001B[1;33m//\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrequires_grad\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "layer3 = AttentionConv(3,17,7,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## flops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False),\n Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False),\n Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = AttentionConv(3,16,7,1)\n",
    "list(layer.children())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([1, 16, 1, 1]) 2X2\n",
      "\n",
      "torch.Size([1, 16, 1, 1]) 3X3\n",
      "\n",
      "torch.Size([1, 16, 2, 2]) 4X4\n",
      "\n",
      "torch.Size([1, 16, 2, 2]) 5X5\n",
      "\n",
      "torch.Size([1, 16, 3, 3]) 6X6\n",
      "\n",
      "torch.Size([1, 16, 3, 3]) 7X7\n",
      "\n",
      "torch.Size([1, 16, 4, 4]) 8X8\n",
      "\n",
      "torch.Size([1, 16, 4, 4]) 9X9\n",
      "\n",
      "torch.Size([1, 16, 5, 5]) 10X10\n",
      "\n",
      "torch.Size([1, 16, 5, 5]) 11X11\n",
      "\n",
      "torch.Size([1, 16, 6, 6]) 12X12\n",
      "\n",
      "torch.Size([1, 16, 6, 6]) 13X13\n",
      "\n",
      "torch.Size([1, 16, 7, 7]) 14X14\n",
      "\n",
      "torch.Size([1, 16, 7, 7]) 15X15\n",
      "\n",
      "torch.Size([1, 16, 8, 8]) 16X16\n",
      "\n",
      "torch.Size([1, 16, 8, 8]) 17X17\n",
      "\n",
      "torch.Size([1, 16, 9, 9]) 18X18\n",
      "\n",
      "torch.Size([1, 16, 9, 9]) 19X19\n",
      "\n",
      "torch.Size([1, 16, 10, 10]) 20X20\n",
      "\n",
      "torch.Size([1, 16, 10, 10]) 21X21\n",
      "\n",
      "torch.Size([1, 16, 11, 11]) 22X22\n",
      "\n",
      "torch.Size([1, 16, 11, 11]) 23X23\n",
      "\n",
      "torch.Size([1, 16, 12, 12]) 24X24\n",
      "\n",
      "torch.Size([1, 16, 12, 12]) 25X25\n",
      "\n",
      "torch.Size([1, 16, 13, 13]) 26X26\n",
      "\n",
      "torch.Size([1, 16, 13, 13]) 27X27\n",
      "\n",
      "torch.Size([1, 16, 14, 14]) 28X28\n",
      "\n",
      "torch.Size([1, 16, 14, 14]) 29X29\n",
      "\n",
      "torch.Size([1, 16, 15, 15]) 30X30\n",
      "\n",
      "torch.Size([1, 16, 15, 15]) 31X31\n",
      "\n",
      "torch.Size([1, 16, 16, 16]) 32X32\n",
      "\n",
      "torch.Size([1, 16, 16, 16]) 33X33\n",
      "\n",
      "torch.Size([1, 16, 17, 17]) 34X34\n",
      "\n",
      "torch.Size([1, 16, 17, 17]) 35X35\n",
      "\n",
      "torch.Size([1, 16, 18, 18]) 36X36\n",
      "\n",
      "torch.Size([1, 16, 18, 18]) 37X37\n",
      "\n",
      "torch.Size([1, 16, 19, 19]) 38X38\n",
      "\n",
      "torch.Size([1, 16, 19, 19]) 39X39\n",
      "\n",
      "torch.Size([1, 16, 20, 20]) 40X40\n",
      "\n",
      "torch.Size([1, 16, 20, 20]) 41X41\n",
      "\n",
      "torch.Size([1, 16, 21, 21]) 42X42\n",
      "\n",
      "torch.Size([1, 16, 21, 21]) 43X43\n",
      "\n",
      "torch.Size([1, 16, 22, 22]) 44X44\n",
      "\n",
      "torch.Size([1, 16, 22, 22]) 45X45\n",
      "\n",
      "torch.Size([1, 16, 23, 23]) 46X46\n",
      "\n",
      "torch.Size([1, 16, 23, 23]) 47X47\n",
      "\n",
      "torch.Size([1, 16, 24, 24]) 48X48\n",
      "\n",
      "torch.Size([1, 16, 24, 24]) 49X49\n",
      "\n",
      "torch.Size([1, 16, 25, 25]) 50X50\n",
      "\n",
      "torch.Size([1, 16, 25, 25]) 51X51\n",
      "\n",
      "torch.Size([1, 16, 26, 26]) 52X52\n",
      "\n",
      "torch.Size([1, 16, 26, 26]) 53X53\n",
      "\n",
      "torch.Size([1, 16, 27, 27]) 54X54\n",
      "\n",
      "torch.Size([1, 16, 27, 27]) 55X55\n",
      "\n",
      "torch.Size([1, 16, 28, 28]) 56X56\n",
      "\n",
      "torch.Size([1, 16, 28, 28]) 57X57\n",
      "\n",
      "torch.Size([1, 16, 29, 29]) 58X58\n",
      "\n",
      "torch.Size([1, 16, 29, 29]) 59X59\n",
      "\n",
      "torch.Size([1, 16, 30, 30]) 60X60\n",
      "\n",
      "torch.Size([1, 16, 30, 30]) 61X61\n",
      "\n",
      "torch.Size([1, 16, 31, 31]) 62X62\n",
      "\n",
      "torch.Size([1, 16, 31, 31]) 63X63\n",
      "\n",
      "torch.Size([1, 16, 32, 32]) 64X64\n"
     ]
    }
   ],
   "source": [
    "layer = AttentionConv(3,16,7,2)\n",
    "for i in range(2,65):\n",
    "    print()\n",
    "    inp = torch.rand(1,3,i,i)\n",
    "    out = layer(inp)\n",
    "    print(out.size(), str(i)+\"X\"+str(i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform size output test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from OFA_mbv3_extended.networks.layers.static_layers.stat_layers import MBConvLayer\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "mb_conv = MBConvLayer(3,3,7,2,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "for i in range(3,100):\n",
    "    for j in range(3,100):\n",
    "        x = torch.ones([1,3,i,j])\n",
    "\n",
    "        y = mb_conv(x)\n",
    "        y = y.size()\n",
    "        z = F.max_pool2d(x, 2, 2, 0, 1, True).size()\n",
    "        assert(y==z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 2, 2])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_conv = MBConvLayer(3,3,3,2,4)\n",
    "x = torch.ones([1,3,3,3])\n",
    "x = mb_conv(x)\n",
    "x.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### >> max 5 applications, 48 minimum size allowed for image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}