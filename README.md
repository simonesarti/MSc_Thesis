# A Journey to Improve Neural Architecture Search: Advancements in Neural Architecture Transfer and Once-For-All

This work is based on [Once-For-All](https://arxiv.org/pdf/1908.09791.pdf) ([GitHub](https://github.com/mit-han-lab/once-for-all)) and [Neural Architecture Transfer](https://arxiv.org/pdf/2005.05859.pdf) ([GitHub](https://github.com/human-analysis/neural-architecture-transfer)).

This repository contains the code and scripts to run the experiments, as well as those to collect and analyse the results.

The thesis PDF can be found [here](./thesis/).

The following research papers are based on this thesis:
* [Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks via Aggregated Early Exits](https://arxiv.org/pdf/2301.12168.pdf) (code [here](https://github.com/simonesarti/AEP))
* [Enhancing Once-For-All: A Study on Parallel Blocks, Skip Connections and Early Exits](https://arxiv.org/pdf/2302.01888.pdf)
* [Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in Multi-Objective Neural Architecture Search](https://arxiv.org/pdf/2307.00960.pdf)
